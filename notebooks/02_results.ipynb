{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6917f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 5)\n",
    "plt.rcParams[\"axes.grid\"] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467a3771",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path(\"..\")\n",
    "\n",
    "ANN_PATH = BASE_DIR / \"data\" / \"annotations\" / \"annotations.csv\"\n",
    "\n",
    "TEST_IMAGES_DIR = BASE_DIR / \"data\" / \"images\" / \"test\"\n",
    "TEST_LIST_TXT   = \"C:/Users/joano/Desktop/trabajo_final_master/data/meta/exp1/datasets/v5_full/labels/test\"\n",
    "DATASET_YAML_ORIG = Path(r\"C:\\Users\\joano\\Desktop\\trabajo_final_master\\data\\meta\\exp1\\datasets\\v5_full\\dataset.yaml\")\n",
    "\n",
    "V7_FULL_WEIGHTS = BASE_DIR / \"runs\" / \"exp1\" / \"v5_full_seed999\" / \"weights\" / \"best.pt\"\n",
    "\n",
    "CONF_TH = 0.25\n",
    "IOU_NMS = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3944671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>image_width</th>\n",
       "      <th>image_height</th>\n",
       "      <th>class_name</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>tipo_obstaculo</th>\n",
       "      <th>temporalidad</th>\n",
       "      <th>...</th>\n",
       "      <th>box_width</th>\n",
       "      <th>box_height</th>\n",
       "      <th>box_area</th>\n",
       "      <th>img_area</th>\n",
       "      <th>box_width_rel</th>\n",
       "      <th>box_height_rel</th>\n",
       "      <th>box_area_rel</th>\n",
       "      <th>cx_rel</th>\n",
       "      <th>cy_rel</th>\n",
       "      <th>box_aspect_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gsv-amsterdam-1071-Obstacle.png</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>960.0</td>\n",
       "      <td>no_obstaculo</td>\n",
       "      <td>266.877470</td>\n",
       "      <td>0.0</td>\n",
       "      <td>433.833992</td>\n",
       "      <td>107.509881</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>166.956522</td>\n",
       "      <td>107.509881</td>\n",
       "      <td>17949.475855</td>\n",
       "      <td>1382400.0</td>\n",
       "      <td>0.115942</td>\n",
       "      <td>0.111989</td>\n",
       "      <td>0.012984</td>\n",
       "      <td>0.243303</td>\n",
       "      <td>0.055995</td>\n",
       "      <td>1.552941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gsv-amsterdam-1071-Obstacle.png</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>960.0</td>\n",
       "      <td>no_obstaculo</td>\n",
       "      <td>135.335968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>190.988142</td>\n",
       "      <td>118.893281</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>55.652174</td>\n",
       "      <td>118.893281</td>\n",
       "      <td>6616.669531</td>\n",
       "      <td>1382400.0</td>\n",
       "      <td>0.038647</td>\n",
       "      <td>0.123847</td>\n",
       "      <td>0.004786</td>\n",
       "      <td>0.113307</td>\n",
       "      <td>0.061924</td>\n",
       "      <td>0.468085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gsv-amsterdam-1071-Obstacle.png</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>960.0</td>\n",
       "      <td>no_obstaculo</td>\n",
       "      <td>761.422925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>809.486166</td>\n",
       "      <td>327.588933</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>48.063241</td>\n",
       "      <td>327.588933</td>\n",
       "      <td>15744.985861</td>\n",
       "      <td>1382400.0</td>\n",
       "      <td>0.033377</td>\n",
       "      <td>0.341238</td>\n",
       "      <td>0.011390</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.170619</td>\n",
       "      <td>0.146718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          image_id  image_width  image_height    class_name  \\\n",
       "0  gsv-amsterdam-1071-Obstacle.png       1440.0         960.0  no_obstaculo   \n",
       "1  gsv-amsterdam-1071-Obstacle.png       1440.0         960.0  no_obstaculo   \n",
       "2  gsv-amsterdam-1071-Obstacle.png       1440.0         960.0  no_obstaculo   \n",
       "\n",
       "         xmin  ymin        xmax        ymax tipo_obstaculo temporalidad  ...  \\\n",
       "0  266.877470   0.0  433.833992  107.509881            NaN          NaN  ...   \n",
       "1  135.335968   0.0  190.988142  118.893281            NaN          NaN  ...   \n",
       "2  761.422925   0.0  809.486166  327.588933            NaN          NaN  ...   \n",
       "\n",
       "    box_width  box_height      box_area   img_area  box_width_rel  \\\n",
       "0  166.956522  107.509881  17949.475855  1382400.0       0.115942   \n",
       "1   55.652174  118.893281   6616.669531  1382400.0       0.038647   \n",
       "2   48.063241  327.588933  15744.985861  1382400.0       0.033377   \n",
       "\n",
       "   box_height_rel  box_area_rel    cx_rel    cy_rel  box_aspect_ratio  \n",
       "0        0.111989      0.012984  0.243303  0.055995          1.552941  \n",
       "1        0.123847      0.004786  0.113307  0.061924          0.468085  \n",
       "2        0.341238      0.011390  0.545455  0.170619          0.146718  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(ANN_PATH)\n",
    "\n",
    "for col in [\"image_width\", \"image_height\", \"xmin\", \"ymin\", \"xmax\", \"ymax\"]:\n",
    "    df[col] = df[col].astype(float)\n",
    "\n",
    "df[\"box_width\"]  = df[\"xmax\"] - df[\"xmin\"]\n",
    "df[\"box_height\"] = df[\"ymax\"] - df[\"ymin\"]\n",
    "df[\"box_area\"]   = df[\"box_width\"] * df[\"box_height\"]\n",
    "\n",
    "df[\"img_area\"]   = df[\"image_width\"] * df[\"image_height\"]\n",
    "df[\"box_width_rel\"]  = df[\"box_width\"]  / df[\"image_width\"]\n",
    "df[\"box_height_rel\"] = df[\"box_height\"] / df[\"image_height\"]\n",
    "df[\"box_area_rel\"]   = df[\"box_area\"]   / df[\"img_area\"]\n",
    "\n",
    "df[\"cx_rel\"] = (df[\"xmin\"] + df[\"xmax\"]) / 2 / df[\"image_width\"]\n",
    "df[\"cy_rel\"] = (df[\"ymin\"] + df[\"ymax\"]) / 2 / df[\"image_height\"]\n",
    "df[\"box_aspect_ratio\"] = df[\"box_width\"] / df[\"box_height\"]\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab7ba386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_width</th>\n",
       "      <th>image_height</th>\n",
       "      <th>n_objects</th>\n",
       "      <th>n_classes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>image_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gsv-amsterdam-1071-Obstacle.png</th>\n",
       "      <td>1440.0</td>\n",
       "      <td>960.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gsv-amsterdam-1081-Obstacle.png</th>\n",
       "      <td>1440.0</td>\n",
       "      <td>960.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gsv-amsterdam-1105-Obstacle.png</th>\n",
       "      <td>1440.0</td>\n",
       "      <td>960.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gsv-amsterdam-1109-Obstacle.png</th>\n",
       "      <td>1440.0</td>\n",
       "      <td>960.0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gsv-amsterdam-1114-Obstacle.png</th>\n",
       "      <td>1440.0</td>\n",
       "      <td>960.0</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 image_width  image_height  n_objects  \\\n",
       "image_id                                                                \n",
       "gsv-amsterdam-1071-Obstacle.png       1440.0         960.0          5   \n",
       "gsv-amsterdam-1081-Obstacle.png       1440.0         960.0          4   \n",
       "gsv-amsterdam-1105-Obstacle.png       1440.0         960.0          4   \n",
       "gsv-amsterdam-1109-Obstacle.png       1440.0         960.0          9   \n",
       "gsv-amsterdam-1114-Obstacle.png       1440.0         960.0         10   \n",
       "\n",
       "                                 n_classes  \n",
       "image_id                                    \n",
       "gsv-amsterdam-1071-Obstacle.png          3  \n",
       "gsv-amsterdam-1081-Obstacle.png          3  \n",
       "gsv-amsterdam-1105-Obstacle.png          3  \n",
       "gsv-amsterdam-1109-Obstacle.png          4  \n",
       "gsv-amsterdam-1114-Obstacle.png          4  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_df = (\n",
    "    df.groupby(\"image_id\")\n",
    "      .agg(\n",
    "          image_width=(\"image_width\", \"first\"),\n",
    "          image_height=(\"image_height\", \"first\"),\n",
    "          n_objects=(\"class_name\", \"count\"),\n",
    "          n_classes=(\"class_name\", \"nunique\"),\n",
    "      )\n",
    ")\n",
    "\n",
    "img_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5300d3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overlap por imagen: 100%|██████████| 1250/1250 [00:00<00:00, 1885.62it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_objects</th>\n",
       "      <th>n_classes</th>\n",
       "      <th>overlap_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1250.00000</td>\n",
       "      <td>1250.00000</td>\n",
       "      <td>1250.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.00640</td>\n",
       "      <td>3.44320</td>\n",
       "      <td>0.181839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.20301</td>\n",
       "      <td>0.54462</td>\n",
       "      <td>0.189746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.00000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.00000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.00000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>32.00000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        n_objects   n_classes  overlap_ratio\n",
       "count  1250.00000  1250.00000    1250.000000\n",
       "mean      7.00640     3.44320       0.181839\n",
       "std       4.20301     0.54462       0.189746\n",
       "min       1.00000     1.00000       0.000000\n",
       "25%       4.00000     3.00000       0.066667\n",
       "50%       6.00000     3.00000       0.133333\n",
       "75%       9.00000     4.00000       0.200000\n",
       "max      32.00000     4.00000       1.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def iou(box_a, box_b):\n",
    "    xa1, ya1, xa2, ya2 = box_a\n",
    "    xb1, yb1, xb2, yb2 = box_b\n",
    "\n",
    "    inter_x1 = max(xa1, xb1)\n",
    "    inter_y1 = max(ya1, yb1)\n",
    "    inter_x2 = min(xa2, xb2)\n",
    "    inter_y2 = min(ya2, yb2)\n",
    "\n",
    "    inter_w = max(0, inter_x2 - inter_x1)\n",
    "    inter_h = max(0, inter_y2 - inter_y1)\n",
    "    inter_area = inter_w * inter_h\n",
    "\n",
    "    area_a = max(0, (xa2 - xa1)) * max(0, (ya2 - ya1))\n",
    "    area_b = max(0, (xb2 - xb1)) * max(0, (yb2 - yb1))\n",
    "\n",
    "    union = area_a + area_b - inter_area\n",
    "    if union <= 0:\n",
    "        return 0.0\n",
    "    return inter_area / union\n",
    "\n",
    "overlap_list = []\n",
    "iou_threshold = 0.1\n",
    "\n",
    "for img_id, group in tqdm(df.groupby(\"image_id\"), desc=\"Overlap por imagen\"):\n",
    "    boxes = group[[\"xmin\", \"ymin\", \"xmax\", \"ymax\"]].values\n",
    "    n = len(boxes)\n",
    "\n",
    "    if n < 2:\n",
    "        overlap_ratio = 0.0\n",
    "    else:\n",
    "        total_pairs = n * (n - 1) / 2\n",
    "        overlapping_pairs = 0\n",
    "        for i in range(n):\n",
    "            for j in range(i + 1, n):\n",
    "                if iou(boxes[i], boxes[j]) > iou_threshold:\n",
    "                    overlapping_pairs += 1\n",
    "        overlap_ratio = overlapping_pairs / total_pairs\n",
    "\n",
    "    overlap_list.append((img_id, overlap_ratio))\n",
    "\n",
    "overlap_df = pd.DataFrame(overlap_list, columns=[\"image_id\", \"overlap_ratio\"]).set_index(\"image_id\")\n",
    "img_df = img_df.join(overlap_df, how=\"left\")\n",
    "img_df[\"overlap_ratio\"] = img_df[\"overlap_ratio\"].fillna(0.0)\n",
    "\n",
    "img_df[[\"n_objects\", \"n_classes\", \"overlap_ratio\"]].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496fe0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Umbral baja/media: 0.2204650188521156\n",
      "Umbral media/alta: 0.273435972629521\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "complexity_level\n",
       "alta     406\n",
       "baja     421\n",
       "media    423\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obst_counts = (\n",
    "    df[df[\"class_name\"] == \"obstaculo\"]\n",
    "    .groupby(\"image_id\")[\"class_name\"]\n",
    "    .count()\n",
    "    .rename(\"n_obstaculo\")\n",
    ")\n",
    "\n",
    "no_obst_counts = (\n",
    "    df[df[\"class_name\"] == \"no_obstaculo\"]\n",
    "    .groupby(\"image_id\")[\"class_name\"]\n",
    "    .count()\n",
    "    .rename(\"n_no_obstaculo\")\n",
    ")\n",
    "\n",
    "img_df = img_df.join(obst_counts, how=\"left\").join(no_obst_counts, how=\"left\")\n",
    "img_df[\"n_obstaculo\"] = img_df[\"n_obstaculo\"].fillna(0).astype(int)\n",
    "img_df[\"n_no_obstaculo\"] = img_df[\"n_no_obstaculo\"].fillna(0).astype(int)\n",
    "\n",
    "# Normalizaciones\n",
    "features = [\"n_objects\", \"n_classes\", \"n_obstaculo\", \"n_no_obstaculo\"]\n",
    "for f in features:\n",
    "    f_min, f_max = img_df[f].min(), img_df[f].max()\n",
    "    img_df[f + \"_norm\"] = (img_df[f] - f_min) / (f_max - f_min) if f_max > f_min else 0.0\n",
    "\n",
    "# Índice ponderado\n",
    "img_df[\"complexity_index\"] = (\n",
    "    0.25 * img_df[\"n_objects_norm\"]\n",
    "    + 0.15 * img_df[\"n_classes_norm\"]\n",
    "    + 0.2  * img_df[\"n_obstaculo_norm\"]\n",
    "    + 0.15 * img_df[\"n_no_obstaculo_norm\"]\n",
    "    + 0.25 * img_df[\"overlap_ratio\"]\n",
    ")\n",
    "\n",
    "q_low, q_high = img_df[\"complexity_index\"].quantile([1/3, 2/3])\n",
    "print(\"Umbral baja/media:\", q_low)\n",
    "print(\"Umbral media/alta:\", q_high)\n",
    "\n",
    "def assign_complexity_level(x, q1, q2):\n",
    "    if x <= q1:\n",
    "        return \"baja\"\n",
    "    elif x <= q2:\n",
    "        return \"media\"\n",
    "    else:\n",
    "        return \"alta\"\n",
    "\n",
    "img_df[\"complexity_level\"] = img_df[\"complexity_index\"].apply(lambda x: assign_complexity_level(x, q_low, q_high))\n",
    "img_df[\"complexity_level\"].value_counts().sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b798da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N test images: 125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[WindowsPath('../data/images/test/gsv-amsterdam-1105-Obstacle.png'),\n",
       " WindowsPath('../data/images/test/gsv-amsterdam-233-Obstacle.png'),\n",
       " WindowsPath('../data/images/test/gsv-amsterdam-34-Obstacle.png')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exts = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\"}\n",
    "test_images = sorted([p for p in Path(TEST_IMAGES_DIR).iterdir() if p.suffix.lower() in exts])\n",
    "\n",
    "print(\"N test images:\", len(test_images))\n",
    "test_images[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7dde848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapeadas en test: 124 | missing: 1126\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "complexity_level\n",
       "alta     44\n",
       "baja     32\n",
       "media    48\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_to_path = {p.stem: p.resolve() for p in test_images}\n",
    "\n",
    "rows = []\n",
    "missing = 0\n",
    "\n",
    "for img_id in img_df.index.astype(str):\n",
    "    stem = Path(img_id).stem\n",
    "    p = stem_to_path.get(stem, None)\n",
    "    if p is None:\n",
    "        missing += 1\n",
    "        continue\n",
    "    rows.append((img_id, p))\n",
    "\n",
    "print(\"Mapeadas en test:\", len(rows), \"| missing:\", missing)\n",
    "\n",
    "test_map = pd.DataFrame(rows, columns=[\"image_id\", \"image_path\"]).set_index(\"image_id\")\n",
    "img_test_df = img_df.join(test_map, how=\"inner\")\n",
    "\n",
    "img_test_df[\"complexity_level\"].value_counts().sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'obstaculo': 0, 'no_obstaculo': 1, 'acera': 2, 'carretera': 3}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig = yaml.safe_load(Path(DATASET_YAML_ORIG).read_text(encoding=\"utf-8\"))\n",
    "names_dict = orig[\"names\"]\n",
    "\n",
    "cls2id = {v: int(k) for k, v in names_dict.items()}\n",
    "cls2id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "788c2bc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baja': 32, 'media': 48, 'alta': 44}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level_to_paths = {\n",
    "    lvl: img_test_df[img_test_df[\"complexity_level\"] == lvl][\"image_path\"].astype(str).tolist()\n",
    "    for lvl in [\"baja\", \"media\", \"alta\"]\n",
    "}\n",
    "{lvl: len(v) for lvl, v in level_to_paths.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8795992f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_yolo_labels_from_csv(df_ann: pd.DataFrame, out_labels_dir: Path, cls2id: dict):\n",
    "    out_labels_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for img_id, g in df_ann.groupby(\"image_id\"):\n",
    "        lines = []\n",
    "        W = float(g[\"image_width\"].iloc[0])\n",
    "        H = float(g[\"image_height\"].iloc[0])\n",
    "\n",
    "        for _, r in g.iterrows():\n",
    "            cname = str(r[\"class_name\"])\n",
    "            if cname not in cls2id:\n",
    "                continue\n",
    "            cid = cls2id[cname]\n",
    "\n",
    "            xmin, ymin, xmax, ymax = map(float, [r[\"xmin\"], r[\"ymin\"], r[\"xmax\"], r[\"ymax\"]])\n",
    "\n",
    "            xmin = max(0.0, min(xmin, W))\n",
    "            xmax = max(0.0, min(xmax, W))\n",
    "            ymin = max(0.0, min(ymin, H))\n",
    "            ymax = max(0.0, min(ymax, H))\n",
    "\n",
    "            bw = max(0.0, xmax - xmin)\n",
    "            bh = max(0.0, ymax - ymin)\n",
    "            if bw <= 0 or bh <= 0:\n",
    "                continue\n",
    "\n",
    "            cx = xmin + bw / 2.0\n",
    "            cy = ymin + bh / 2.0\n",
    "\n",
    "            xc = cx / W\n",
    "            yc = cy / H\n",
    "            wn = bw / W\n",
    "            hn = bh / H\n",
    "\n",
    "            lines.append(f\"{cid} {xc:.6f} {yc:.6f} {wn:.6f} {hn:.6f}\")\n",
    "\n",
    "        stem = Path(str(img_id)).stem\n",
    "        (out_labels_dir / f\"{stem}.txt\").write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n",
    "\n",
    "EVAL_ROOT = BASE_DIR / \"notebooks\" / \"eval_by_complexity_v7_full\"\n",
    "EVAL_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def build_eval_dataset_for_level(level: str, image_paths: list[str], df_full: pd.DataFrame):\n",
    "    level_root = EVAL_ROOT / level\n",
    "    img_dir = level_root / \"images\" / \"test\"\n",
    "    lab_dir = level_root / \"labels\" / \"test\"\n",
    "    img_dir.mkdir(parents=True, exist_ok=True)\n",
    "    lab_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    stems = set()\n",
    "    for p in image_paths:\n",
    "        p = Path(p)\n",
    "        stems.add(p.stem)\n",
    "        dst = img_dir / p.name\n",
    "        if not dst.exists():\n",
    "            shutil.copy2(p, dst)\n",
    "\n",
    "    df_sub = df_full.copy()\n",
    "    df_sub[\"_stem\"] = df_sub[\"image_id\"].astype(str).apply(lambda x: Path(x).stem)\n",
    "    df_sub = df_sub[df_sub[\"_stem\"].isin(stems)].drop(columns=[\"_stem\"])\n",
    "\n",
    "    write_yolo_labels_from_csv(df_sub, lab_dir, cls2id)\n",
    "\n",
    "    eval_yaml = {\n",
    "        \"path\": str(level_root),\n",
    "        \"train\": \"images/test\",\n",
    "        \"val\": \"images/test\",\n",
    "        \"test\": \"images/test\",\n",
    "        \"names\": names_dict,\n",
    "    }\n",
    "    yaml_path = level_root / \"dataset.yaml\"\n",
    "    yaml_path.write_text(yaml.safe_dump(eval_yaml, sort_keys=False), encoding=\"utf-8\")\n",
    "\n",
    "    return yaml_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff15d6f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baja': WindowsPath('../notebooks/eval_by_complexity_v7_full/baja/dataset.yaml'),\n",
       " 'media': WindowsPath('../notebooks/eval_by_complexity_v7_full/media/dataset.yaml'),\n",
       " 'alta': WindowsPath('../notebooks/eval_by_complexity_v7_full/alta/dataset.yaml')}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level_to_yaml = {}\n",
    "for lvl in [\"baja\", \"media\", \"alta\"]:\n",
    "    level_to_yaml[lvl] = build_eval_dataset_for_level(lvl, level_to_paths[lvl], df)\n",
    "\n",
    "level_to_yaml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52944edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_metrics(r, class_name: str):\n",
    "    name_to_id = {v: k for k, v in r.names.items()}\n",
    "    if class_name not in name_to_id:\n",
    "        raise ValueError(f\"Clase '{class_name}' no existe en r.names: {r.names}\")\n",
    "    cid = int(name_to_id[class_name])\n",
    "\n",
    "    out = {\"class_id\": cid, \"class_name\": class_name}\n",
    "\n",
    "    out[\"precision\"] = float(r.box.p[cid]) if hasattr(r.box, \"p\") and r.box.p is not None else np.nan\n",
    "    out[\"recall\"]    = float(r.box.r[cid]) if hasattr(r.box, \"r\") and r.box.r is not None else np.nan\n",
    "\n",
    "    out[\"mAP50\"]     = float(r.box.ap50[cid]) if hasattr(r.box, \"ap50\") and r.box.ap50 is not None else np.nan\n",
    "    out[\"mAP50-95\"]  = float(r.box.ap[cid]) if hasattr(r.box, \"ap\") and r.box.ap is not None else np.nan\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495e8737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.4.14  Python-3.11.13 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 2060, 6144MiB)\n",
      "YOLO11s summary (fused): 100 layers, 9,414,348 parameters, 0 gradients, 21.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.1 ms, read: 1102.697.1 MB/s, size: 3050.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\joano\\Desktop\\trabajo_final_master\\notebooks\\eval_by_complexity_v7_full\\baja\\labels\\test.cache... 32 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 32/32  0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 2/2 2.4s/it 4.8s<14.1s\n",
      "                   all         32        147      0.638      0.778      0.681      0.545\n",
      "Speed: 4.3ms preprocess, 11.9ms inference, 0.0ms loss, 5.0ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\joano\\Desktop\\trabajo_final_master\\notebooks\\runs\\notebooks\\eval_by_complexity_v7_full\\runs\\val_baja3\u001b[0m\n",
      "Ultralytics 8.4.14  Python-3.11.13 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 2060, 6144MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 974.148.3 MB/s, size: 3028.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\joano\\Desktop\\trabajo_final_master\\notebooks\\eval_by_complexity_v7_full\\media\\labels\\test.cache... 48 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 48/48  0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 1.7s/it 5.1s1.8s5s\n",
      "                   all         48        293      0.665      0.674      0.684      0.516\n",
      "Speed: 4.9ms preprocess, 12.7ms inference, 0.0ms loss, 6.1ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\joano\\Desktop\\trabajo_final_master\\notebooks\\runs\\notebooks\\eval_by_complexity_v7_full\\runs\\val_media3\u001b[0m\n",
      "Ultralytics 8.4.14  Python-3.11.13 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 2060, 6144MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 1019.5107.2 MB/s, size: 2306.6 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\joano\\Desktop\\trabajo_final_master\\notebooks\\eval_by_complexity_v7_full\\alta\\labels\\test.cache... 44 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 44/44  0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 1.7s/it 5.0s1.9s7s\n",
      "                   all         44        428      0.669      0.597      0.637      0.485\n",
      "Speed: 3.8ms preprocess, 11.5ms inference, 0.0ms loss, 12.6ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\joano\\Desktop\\trabajo_final_master\\notebooks\\runs\\notebooks\\eval_by_complexity_v7_full\\runs\\val_alta3\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>complexity_level</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>mAP50</th>\n",
       "      <th>mAP50-95</th>\n",
       "      <th>n_images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baja</td>\n",
       "      <td>0.636468</td>\n",
       "      <td>0.636656</td>\n",
       "      <td>0.719856</td>\n",
       "      <td>0.529788</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>media</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.559140</td>\n",
       "      <td>0.494368</td>\n",
       "      <td>0.333702</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>alta</td>\n",
       "      <td>0.496855</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.475470</td>\n",
       "      <td>0.323642</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  complexity_level  precision    recall     mAP50  mAP50-95  n_images\n",
       "0             baja   0.636468  0.636656  0.719856  0.529788        32\n",
       "1            media   0.433333  0.559140  0.494368  0.333702        48\n",
       "2             alta   0.496855  0.500000  0.475470  0.323642        44"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLASS_FOCUS = \"obstaculo\"\n",
    "\n",
    "model = YOLO(str(V7_FULL_WEIGHTS))\n",
    "\n",
    "metrics_by_level = []\n",
    "for lvl in [\"baja\", \"media\", \"alta\"]:\n",
    "    yml = level_to_yaml[lvl]\n",
    "\n",
    "    r = model.val(\n",
    "        data=str(yml),\n",
    "        split=\"test\",\n",
    "        conf=CONF_TH,\n",
    "        iou=IOU_NMS,\n",
    "        cache=False,\n",
    "        verbose=False,\n",
    "        project=str(EVAL_ROOT / \"runs\"),\n",
    "        name=f\"val_{lvl}\",\n",
    "    )\n",
    "\n",
    "    cm = get_class_metrics(r, CLASS_FOCUS)\n",
    "\n",
    "    metrics_by_level.append({\n",
    "        \"complexity_level\": lvl,\n",
    "        \"precision\": cm[\"precision\"],\n",
    "        \"recall\": cm[\"recall\"],\n",
    "        \"mAP50\": cm[\"mAP50\"],\n",
    "        \"mAP50-95\": cm[\"mAP50-95\"],\n",
    "        \"n_images\": len(level_to_paths[lvl]),\n",
    "    })\n",
    "\n",
    "metrics_level_df = pd.DataFrame(metrics_by_level)\n",
    "metrics_level_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b244e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 860x460 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Figuras guardadas: ..\\notebooks\\eval_by_complexity_v7_full\\metrics_by_complexity_level_v7_full_framed_color.pdf y ..\\notebooks\\eval_by_complexity_v7_full\\metrics_by_complexity_level_v7_full_framed_color.png\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "order = [\"baja\", \"media\", \"alta\"]\n",
    "m = metrics_level_df.copy()\n",
    "m[\"complexity_level\"] = pd.Categorical(m[\"complexity_level\"], order, ordered=True)\n",
    "m = m.sort_values(\"complexity_level\")\n",
    "\n",
    "metrics = [\"precision\", \"recall\", \"mAP50\", \"mAP50-95\"]\n",
    "\n",
    "x = np.arange(len(order))\n",
    "width = 0.18\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8.6, 4.6))\n",
    "\n",
    "cmap = plt.get_cmap(\"tab10\")\n",
    "metric_colors = {\n",
    "    \"precision\": cmap(0), \n",
    "    \"recall\":    cmap(1),\n",
    "    \"mAP50\":     cmap(2), \n",
    "    \"mAP50-95\":  cmap(3),\n",
    "}\n",
    "\n",
    "for i, met in enumerate(metrics):\n",
    "    xpos = x + (i - (len(metrics) - 1) / 2) * width\n",
    "\n",
    "    vals = m[met].values\n",
    "    bars = ax.bar(\n",
    "        xpos,\n",
    "        vals,\n",
    "        width=width,\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=1.1,\n",
    "        color=metric_colors.get(met, cmap(0)),\n",
    "        alpha=0.85,\n",
    "        label=met,\n",
    "        zorder=3,\n",
    "    )\n",
    "\n",
    "    for b, val in zip(bars, vals):\n",
    "        ax.text(\n",
    "            b.get_x() + b.get_width() / 2,\n",
    "            float(val) + 0.015,\n",
    "            f\"{val:.2f}\",\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=8,\n",
    "            color=\"black\",\n",
    "        )\n",
    "\n",
    "ax.set_title(\n",
    "    \"v7_full en TEST — métricas por complejidad\",\n",
    "    fontsize=18,\n",
    "    fontfamily=\"serif\",\n",
    "    pad=12,\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Nivel de complejidad\", fontsize=13)\n",
    "ax.set_ylabel(\"Valor\", fontsize=13)\n",
    "\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(order, fontsize=12)\n",
    "\n",
    "ax.set_ylim(0, 1.0)\n",
    "\n",
    "ax.grid(\n",
    "    True,\n",
    "    axis=\"y\",\n",
    "    linestyle=\":\",\n",
    "    linewidth=0.9,\n",
    "    alpha=0.30,\n",
    "    zorder=0,\n",
    ")\n",
    "ax.grid(False, axis=\"x\")\n",
    "\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_visible(True)\n",
    "    spine.set_linewidth(1.6)\n",
    "\n",
    "ax.legend(\n",
    "    loc=\"center left\",\n",
    "    bbox_to_anchor=(1.02, 0.5),\n",
    "    frameon=False,\n",
    "    fontsize=11,\n",
    ")\n",
    "\n",
    "fig.tight_layout(rect=[0.0, 0.0, 0.82, 1.0])\n",
    "plt.show()\n",
    "\n",
    "fig_pdf = EVAL_ROOT / \"metrics_by_complexity_level_v7_full_framed_color.pdf\"\n",
    "fig_png = EVAL_ROOT / \"metrics_by_complexity_level_v7_full_framed_color.png\"\n",
    "\n",
    "fig.savefig(fig_pdf, bbox_inches=\"tight\", dpi=300)\n",
    "fig.savefig(fig_png, bbox_inches=\"tight\", dpi=300)\n",
    "\n",
    "print(\"Figuras guardadas:\", fig_pdf, \"y\", fig_png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c0194a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imágenes test: 124\n",
      "BBoxes test: 868\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>city</th>\n",
       "      <th>class_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gsv-amsterdam-1105-Obstacle.png</td>\n",
       "      <td>amsterdam</td>\n",
       "      <td>obstaculo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gsv-amsterdam-1105-Obstacle.png</td>\n",
       "      <td>amsterdam</td>\n",
       "      <td>obstaculo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gsv-amsterdam-1105-Obstacle.png</td>\n",
       "      <td>amsterdam</td>\n",
       "      <td>acera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gsv-amsterdam-1105-Obstacle.png</td>\n",
       "      <td>amsterdam</td>\n",
       "      <td>carretera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>gsv-amsterdam-233-Obstacle.png</td>\n",
       "      <td>amsterdam</td>\n",
       "      <td>obstaculo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            image_id       city class_name\n",
       "9    gsv-amsterdam-1105-Obstacle.png  amsterdam  obstaculo\n",
       "10   gsv-amsterdam-1105-Obstacle.png  amsterdam  obstaculo\n",
       "11   gsv-amsterdam-1105-Obstacle.png  amsterdam      acera\n",
       "12   gsv-amsterdam-1105-Obstacle.png  amsterdam  carretera\n",
       "266   gsv-amsterdam-233-Obstacle.png  amsterdam  obstaculo"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "# Estilo\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "plt.rcParams[\"font.size\"] = 11\n",
    "plt.rcParams[\"axes.linewidth\"] = 0.8\n",
    "\n",
    "def extract_city(image_id: str) -> str:\n",
    "    s = str(image_id)\n",
    "    m = re.search(r\"^gsv-([^-]+(?:-[^-]+)*)-\\d+-\", s)\n",
    "    if m:\n",
    "        city = m.group(1)\n",
    "    else:\n",
    "        parts = s.split(\"-\")\n",
    "        city = parts[1] if len(parts) > 1 else \"unknown\"\n",
    "    return city.lower()\n",
    "\n",
    "df_city = df.copy()\n",
    "df_city[\"city\"] = df_city[\"image_id\"].apply(extract_city)\n",
    "\n",
    "test_image_ids = set(img_test_df.index.astype(str).tolist())\n",
    "\n",
    "df_city_test = df_city[df_city[\"image_id\"].astype(str).isin(test_image_ids)].copy()\n",
    "\n",
    "print(\"Imágenes test:\", len(test_image_ids))\n",
    "print(\"BBoxes test:\", len(df_city_test))\n",
    "df_city_test[[\"image_id\",\"city\",\"class_name\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea3782a",
   "metadata": {},
   "outputs": [],
   "source": [
    "FOCUS_CLASS = \"obstaculo\"\n",
    "NAMES_1CLASS = {0: FOCUS_CLASS}\n",
    "\n",
    "def write_yolo_labels_focus_1class(df_ann: pd.DataFrame, out_labels_dir: Path, focus_class: str):\n",
    "    out_labels_dir.mkdir(parents=True, exist_ok=True)\n",
    "    df_ann = df_ann[df_ann[\"class_name\"].astype(str) == focus_class].copy()\n",
    "\n",
    "    for img_id, g in df_ann.groupby(\"image_id\"):\n",
    "        lines = []\n",
    "        W = float(g[\"image_width\"].iloc[0])\n",
    "        H = float(g[\"image_height\"].iloc[0])\n",
    "\n",
    "        for _, r in g.iterrows():\n",
    "            xmin, ymin, xmax, ymax = map(float, [r[\"xmin\"], r[\"ymin\"], r[\"xmax\"], r[\"ymax\"]])\n",
    "\n",
    "            xmin = max(0.0, min(xmin, W)); xmax = max(0.0, min(xmax, W))\n",
    "            ymin = max(0.0, min(ymin, H)); ymax = max(0.0, min(ymax, H))\n",
    "\n",
    "            bw = max(0.0, xmax - xmin)\n",
    "            bh = max(0.0, ymax - ymin)\n",
    "            if bw <= 0 or bh <= 0:\n",
    "                continue\n",
    "\n",
    "            cx = xmin + bw/2.0\n",
    "            cy = ymin + bh/2.0\n",
    "\n",
    "            xc = cx / W\n",
    "            yc = cy / H\n",
    "            wn = bw / W\n",
    "            hn = bh / H\n",
    "\n",
    "            lines.append(f\"0 {xc:.6f} {yc:.6f} {wn:.6f} {hn:.6f}\")\n",
    "\n",
    "        stem = Path(str(img_id)).stem\n",
    "        (out_labels_dir / f\"{stem}.txt\").write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d922481",
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_CITY_ROOT = BASE_DIR / \"notebooks\" / \"eval_by_city_v7_full_obstaculo\"\n",
    "EVAL_CITY_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def build_eval_dataset_for_city(city: str, img_paths: list[str], df_city_test: pd.DataFrame):\n",
    "    city_root = EVAL_CITY_ROOT / city\n",
    "    img_dir = city_root / \"images\" / \"test\"\n",
    "    lab_dir = city_root / \"labels\" / \"test\"\n",
    "    img_dir.mkdir(parents=True, exist_ok=True)\n",
    "    lab_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    stems = set()\n",
    "    for p in img_paths:\n",
    "        p = Path(p)\n",
    "        stems.add(p.stem)\n",
    "        dst = img_dir / p.name\n",
    "        if not dst.exists():\n",
    "            shutil.copy2(p, dst)\n",
    "\n",
    "    df_sub = df_city_test.copy()\n",
    "    df_sub[\"_stem\"] = df_sub[\"image_id\"].astype(str).apply(lambda x: Path(x).stem)\n",
    "    df_sub = df_sub[df_sub[\"_stem\"].isin(stems)].drop(columns=[\"_stem\"])\n",
    "\n",
    "    write_yolo_labels_focus_1class(df_sub, lab_dir, focus_class=FOCUS_CLASS)\n",
    "\n",
    "    eval_yaml = {\n",
    "        \"path\": str(city_root),\n",
    "        \"train\": \"images/test\",\n",
    "        \"val\": \"images/test\",\n",
    "        \"test\": \"images/test\",\n",
    "        \"names\": NAMES_1CLASS,\n",
    "    }\n",
    "    yaml_path = city_root / \"dataset.yaml\"\n",
    "    yaml_path.write_text(yaml.safe_dump(eval_yaml, sort_keys=False), encoding=\"utf-8\")\n",
    "\n",
    "    return yaml_path, df_sub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc798b83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>n_images</th>\n",
       "      <th>n_obstaculos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>seattle</td>\n",
       "      <td>39</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spgg</td>\n",
       "      <td>13</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cdmx</td>\n",
       "      <td>13</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>columbus</td>\n",
       "      <td>13</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chicago</td>\n",
       "      <td>13</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amsterdam</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>oradell</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>newberg</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>pittsburgh</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         city  n_images  n_obstaculos\n",
       "7     seattle        39            82\n",
       "8        spgg        13            50\n",
       "1        cdmx        13            46\n",
       "3    columbus        13            28\n",
       "2     chicago        13            25\n",
       "0   amsterdam        10            31\n",
       "5     oradell        10             9\n",
       "4     newberg         7            22\n",
       "6  pittsburgh         6            24"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = img_test_df.copy()\n",
    "tmp[\"city\"] = tmp.index.astype(str).map(extract_city)\n",
    "\n",
    "city_to_paths = tmp.groupby(\"city\")[\"image_path\"].apply(lambda s: s.astype(str).tolist()).to_dict()\n",
    "\n",
    "obs_by_city = (\n",
    "    df_city_test[df_city_test[\"class_name\"].astype(str) == FOCUS_CLASS]\n",
    "    .groupby(\"city\")[\"class_name\"].count()\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "city_stats = []\n",
    "for city, paths in city_to_paths.items():\n",
    "    n_imgs = len(paths)\n",
    "    n_obs = int(obs_by_city.get(city, 0))\n",
    "    city_stats.append((city, n_imgs, n_obs))\n",
    "\n",
    "city_stats_df = pd.DataFrame(city_stats, columns=[\"city\", \"n_images\", \"n_obstaculos\"]).sort_values(\"n_images\", ascending=False)\n",
    "city_stats_df.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a366a01d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>n_images</th>\n",
       "      <th>n_obstaculos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>seattle</td>\n",
       "      <td>39</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spgg</td>\n",
       "      <td>13</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cdmx</td>\n",
       "      <td>13</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>columbus</td>\n",
       "      <td>13</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chicago</td>\n",
       "      <td>13</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>amsterdam</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>oradell</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>newberg</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pittsburgh</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         city  n_images  n_obstaculos\n",
       "0     seattle        39            82\n",
       "1        spgg        13            50\n",
       "2        cdmx        13            46\n",
       "3    columbus        13            28\n",
       "4     chicago        13            25\n",
       "5   amsterdam        10            31\n",
       "6     oradell        10             9\n",
       "7     newberg         7            22\n",
       "8  pittsburgh         6            24"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ciudades totales en TEST: 9\n",
      "Ciudades válidas (>= 5 imgs y >= 5 obst): 9\n",
      "Ejemplos valid_cities: ['seattle', 'spgg', 'cdmx', 'columbus', 'chicago', 'amsterdam', 'oradell', 'newberg', 'pittsburgh']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "tmp = img_test_df.copy()\n",
    "tmp[\"city\"] = tmp.index.astype(str).map(extract_city)\n",
    "\n",
    "city_to_paths = tmp.groupby(\"city\")[\"image_path\"].apply(lambda s: s.astype(str).tolist()).to_dict()\n",
    "\n",
    "FOCUS_CLASS = \"obstaculo\"\n",
    "obs_by_city = (\n",
    "    df_city_test[df_city_test[\"class_name\"].astype(str) == FOCUS_CLASS]\n",
    "    .groupby(\"city\")[\"class_name\"]\n",
    "    .count()\n",
    "    .to_dict()\n",
    ")\n",
    "\n",
    "city_stats = []\n",
    "for city, paths in city_to_paths.items():\n",
    "    n_imgs = len(paths)\n",
    "    n_obs = int(obs_by_city.get(city, 0))\n",
    "    city_stats.append((city, n_imgs, n_obs))\n",
    "\n",
    "city_stats_df = (\n",
    "    pd.DataFrame(city_stats, columns=[\"city\", \"n_images\", \"n_obstaculos\"])\n",
    "      .sort_values([\"n_images\", \"n_obstaculos\"], ascending=False)\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "display(city_stats_df.head(20))\n",
    "\n",
    "MIN_IMAGES = 5\n",
    "MIN_OBS_INSTANCES = 5\n",
    "\n",
    "valid_cities = city_stats_df[\n",
    "    (city_stats_df[\"n_images\"] >= MIN_IMAGES) &\n",
    "    (city_stats_df[\"n_obstaculos\"] >= MIN_OBS_INSTANCES)\n",
    "][\"city\"].tolist()\n",
    "\n",
    "print(f\"Ciudades totales en TEST: {len(city_stats_df)}\")\n",
    "print(f\"Ciudades válidas (>= {MIN_IMAGES} imgs y >= {MIN_OBS_INSTANCES} obst): {len(valid_cities)}\")\n",
    "print(\"Ejemplos valid_cities:\", valid_cities[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bbffd2e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.4.14  Python-3.11.13 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 2060, 6144MiB)\n",
      "YOLO11s summary (fused): 100 layers, 9,414,348 parameters, 0 gradients, 21.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 1121.482.1 MB/s, size: 2643.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\joano\\Desktop\\trabajo_final_master\\notebooks\\eval_by_city_v7_full_obstaculo\\seattle\\labels\\test.cache... 37 images, 2 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 39/39  0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 3/3 1.5s/it 4.5s1.4s3s\n",
      "                   all         39         82      0.611      0.683      0.657      0.499\n",
      "Speed: 4.0ms preprocess, 14.4ms inference, 0.1ms loss, 5.2ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\joano\\Desktop\\trabajo_final_master\\notebooks\\runs\\notebooks\\eval_by_city_v7_full_obstaculo\\runs\\val_seattle2\u001b[0m\n",
      "Ultralytics 8.4.14  Python-3.11.13 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 2060, 6144MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 863.457.6 MB/s, size: 2362.8 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\joano\\Desktop\\trabajo_final_master\\notebooks\\eval_by_city_v7_full_obstaculo\\spgg\\labels\\test.cache... 13 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 13/13  0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.4s/it 3.4s\n",
      "                   all         13         50      0.634        0.4      0.448      0.308\n",
      "Speed: 1.2ms preprocess, 13.8ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\joano\\Desktop\\trabajo_final_master\\notebooks\\runs\\notebooks\\eval_by_city_v7_full_obstaculo\\runs\\val_spgg2\u001b[0m\n",
      "Ultralytics 8.4.14  Python-3.11.13 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 2060, 6144MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 1053.198.9 MB/s, size: 2555.8 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\joano\\Desktop\\trabajo_final_master\\notebooks\\eval_by_city_v7_full_obstaculo\\cdmx\\labels\\test.cache... 13 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 13/13  0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.4s/it 3.4s\n",
      "                   all         13         46      0.546      0.471      0.498       0.27\n",
      "Speed: 1.5ms preprocess, 13.3ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\joano\\Desktop\\trabajo_final_master\\notebooks\\runs\\notebooks\\eval_by_city_v7_full_obstaculo\\runs\\val_cdmx2\u001b[0m\n",
      "Ultralytics 8.4.14  Python-3.11.13 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 2060, 6144MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 989.461.3 MB/s, size: 2730.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\joano\\Desktop\\trabajo_final_master\\notebooks\\eval_by_city_v7_full_obstaculo\\columbus\\labels\\test.cache... 13 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 13/13  0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.7s/it 3.7s\n",
      "                   all         13         28      0.369        0.5      0.409      0.294\n",
      "Speed: 1.4ms preprocess, 13.2ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\joano\\Desktop\\trabajo_final_master\\notebooks\\runs\\notebooks\\eval_by_city_v7_full_obstaculo\\runs\\val_columbus2\u001b[0m\n",
      "Ultralytics 8.4.14  Python-3.11.13 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 2060, 6144MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 990.286.8 MB/s, size: 2907.0 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\joano\\Desktop\\trabajo_final_master\\notebooks\\eval_by_city_v7_full_obstaculo\\chicago\\labels\\test.cache... 13 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 13/13  0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.6s/it 3.6s\n",
      "                   all         13         25      0.423       0.56      0.443      0.268\n",
      "Speed: 1.5ms preprocess, 13.2ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\joano\\Desktop\\trabajo_final_master\\notebooks\\runs\\notebooks\\eval_by_city_v7_full_obstaculo\\runs\\val_chicago2\u001b[0m\n",
      "Ultralytics 8.4.14  Python-3.11.13 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 2060, 6144MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 989.761.3 MB/s, size: 3158.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\joano\\Desktop\\trabajo_final_master\\notebooks\\eval_by_city_v7_full_obstaculo\\amsterdam\\labels\\test.cache... 10 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 10/10  0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.5s/it 3.5s\n",
      "                   all         10         31      0.465      0.484      0.478       0.26\n",
      "Speed: 1.5ms preprocess, 12.4ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\joano\\Desktop\\trabajo_final_master\\notebooks\\runs\\notebooks\\eval_by_city_v7_full_obstaculo\\runs\\val_amsterdam2\u001b[0m\n",
      "Ultralytics 8.4.14  Python-3.11.13 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 2060, 6144MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 993.857.2 MB/s, size: 3159.9 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\joano\\Desktop\\trabajo_final_master\\notebooks\\eval_by_city_v7_full_obstaculo\\oradell\\labels\\test.cache... 7 images, 3 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 10/10  0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.2s/it 3.2s\n",
      "                   all         10          9      0.554      0.556      0.487      0.356\n",
      "Speed: 1.5ms preprocess, 12.9ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\joano\\Desktop\\trabajo_final_master\\notebooks\\runs\\notebooks\\eval_by_city_v7_full_obstaculo\\runs\\val_oradell2\u001b[0m\n",
      "Ultralytics 8.4.14  Python-3.11.13 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 2060, 6144MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 937.252.7 MB/s, size: 2570.8 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\joano\\Desktop\\trabajo_final_master\\notebooks\\eval_by_city_v7_full_obstaculo\\newberg\\labels\\test.cache... 7 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 7/7  0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 3.3s/it 3.3s\n",
      "                   all          7         22      0.764      0.589      0.708       0.56\n",
      "Speed: 1.6ms preprocess, 12.2ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\joano\\Desktop\\trabajo_final_master\\notebooks\\runs\\notebooks\\eval_by_city_v7_full_obstaculo\\runs\\val_newberg2\u001b[0m\n",
      "Ultralytics 8.4.14  Python-3.11.13 torch-2.7.1+cu118 CUDA:0 (NVIDIA GeForce RTX 2060, 6144MiB)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 1022.448.4 MB/s, size: 2888.3 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\joano\\Desktop\\trabajo_final_master\\notebooks\\eval_by_city_v7_full_obstaculo\\pittsburgh\\labels\\test.cache... 6 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 6/6  0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 2.9s/it 2.9s\n",
      "                   all          6         24      0.818      0.375      0.572      0.449\n",
      "Speed: 1.4ms preprocess, 14.2ms inference, 0.0ms loss, 1.1ms postprocess per image\n",
      "Results saved to \u001b[1mC:\\Users\\joano\\Desktop\\trabajo_final_master\\notebooks\\runs\\notebooks\\eval_by_city_v7_full_obstaculo\\runs\\val_pittsburgh2\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>n_images</th>\n",
       "      <th>n_obstaculos</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>mAP50</th>\n",
       "      <th>mAP50-95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>newberg</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>0.764156</td>\n",
       "      <td>0.589210</td>\n",
       "      <td>0.708452</td>\n",
       "      <td>0.560284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>seattle</td>\n",
       "      <td>39</td>\n",
       "      <td>82</td>\n",
       "      <td>0.611368</td>\n",
       "      <td>0.682927</td>\n",
       "      <td>0.656547</td>\n",
       "      <td>0.499427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>pittsburgh</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>0.818135</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.572091</td>\n",
       "      <td>0.449396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>oradell</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>0.553859</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.486944</td>\n",
       "      <td>0.356191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spgg</td>\n",
       "      <td>13</td>\n",
       "      <td>50</td>\n",
       "      <td>0.634294</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.447668</td>\n",
       "      <td>0.307875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>columbus</td>\n",
       "      <td>13</td>\n",
       "      <td>28</td>\n",
       "      <td>0.368923</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.408569</td>\n",
       "      <td>0.294059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cdmx</td>\n",
       "      <td>13</td>\n",
       "      <td>46</td>\n",
       "      <td>0.545950</td>\n",
       "      <td>0.470631</td>\n",
       "      <td>0.497979</td>\n",
       "      <td>0.269748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chicago</td>\n",
       "      <td>13</td>\n",
       "      <td>25</td>\n",
       "      <td>0.422922</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.443484</td>\n",
       "      <td>0.267721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>amsterdam</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>0.464676</td>\n",
       "      <td>0.483871</td>\n",
       "      <td>0.477593</td>\n",
       "      <td>0.260499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         city  n_images  n_obstaculos  precision    recall     mAP50  mAP50-95\n",
       "7     newberg         7            22   0.764156  0.589210  0.708452  0.560284\n",
       "0     seattle        39            82   0.611368  0.682927  0.656547  0.499427\n",
       "8  pittsburgh         6            24   0.818135  0.375000  0.572091  0.449396\n",
       "6     oradell        10             9   0.553859  0.555556  0.486944  0.356191\n",
       "1        spgg        13            50   0.634294  0.400000  0.447668  0.307875\n",
       "3    columbus        13            28   0.368923  0.500000  0.408569  0.294059\n",
       "2        cdmx        13            46   0.545950  0.470631  0.497979  0.269748\n",
       "4     chicago        13            25   0.422922  0.560000  0.443484  0.267721\n",
       "5   amsterdam        10            31   0.464676  0.483871  0.477593  0.260499"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = YOLO(str(V7_FULL_WEIGHTS))\n",
    "\n",
    "rows = []\n",
    "for city in valid_cities:\n",
    "    yml, df_sub = build_eval_dataset_for_city(city, city_to_paths[city], df_city_test)\n",
    "\n",
    "    r = model.val(\n",
    "        data=str(yml),\n",
    "        split=\"test\",\n",
    "        conf=CONF_TH,\n",
    "        iou=IOU_NMS,\n",
    "        cache=False,\n",
    "        verbose=False,\n",
    "        project=str(EVAL_CITY_ROOT / \"runs\"),\n",
    "        name=f\"val_{city}\",\n",
    "    )\n",
    "\n",
    "    rows.append({\n",
    "        \"city\": city,\n",
    "        \"n_images\": len(city_to_paths[city]),\n",
    "        \"n_obstaculos\": int(obs_by_city.get(city, 0)),\n",
    "        \"precision\": float(getattr(r.box, \"mp\", np.nan)),\n",
    "        \"recall\": float(getattr(r.box, \"mr\", np.nan)),\n",
    "        \"mAP50\": float(getattr(r.box, \"map50\", np.nan)),\n",
    "        \"mAP50-95\": float(getattr(r.box, \"map\", np.nan)),\n",
    "    })\n",
    "\n",
    "city_metrics_df = pd.DataFrame(rows).sort_values(\"mAP50-95\", ascending=False)\n",
    "city_metrics_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dff4e39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado: ..\\notebooks\\eval_by_city_v7_full_obstaculo\\metrics_by_city_v7_full_obstaculo.csv\n"
     ]
    }
   ],
   "source": [
    "out_csv = EVAL_CITY_ROOT / \"metrics_by_city_v7_full_obstaculo.csv\"\n",
    "city_metrics_df.to_csv(out_csv, index=False)\n",
    "print(\"Guardado:\", out_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3627922e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1050x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1050x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def hatch_cycle(n: int):\n",
    "    h = [\"\", \"//\", \"\\\\\\\\\", \"xx\", \"..\", \"oo\", \"++\", \"--\", \"**\", \"||\"]\n",
    "    return [h[i % len(h)] for i in range(n)]\n",
    "\n",
    "def plot_city_ranking(df, metric=\"mAP50-95\", topk=10, title=None, out_base=None):\n",
    "    d = df.sort_values(metric, ascending=False).head(topk).copy()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10.5, 3.6))\n",
    "    x = np.arange(len(d))\n",
    "    hatches = hatch_cycle(len(d))\n",
    "\n",
    "    bars = ax.bar(x, d[metric].values, edgecolor=\"black\", linewidth=1.4, facecolor=\"white\", zorder=3)\n",
    "\n",
    "    for i, b in enumerate(bars):\n",
    "        b.set_hatch(hatches[i])\n",
    "        ax.text(b.get_x()+b.get_width()/2, b.get_height()+0.01, f\"{b.get_height():.2f}\",\n",
    "                ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "\n",
    "    ax.set_title(title or f\"Ranking por ciudad — {metric}\", fontsize=18, fontfamily=\"serif\", pad=12)\n",
    "    ax.set_ylabel(metric)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(d[\"city\"].tolist(), rotation=25, ha=\"right\")\n",
    "\n",
    "    ax.grid(True, axis=\"y\", linestyle=\":\", linewidth=0.9, alpha=0.35, zorder=0)\n",
    "\n",
    "    # marco completo\n",
    "    for s in ax.spines.values():\n",
    "        s.set_visible(True)\n",
    "        s.set_linewidth(1.6)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    if out_base:\n",
    "        fig.savefig(str(out_base) + \".pdf\", bbox_inches=\"tight\", dpi=300)\n",
    "        fig.savefig(str(out_base) + \".png\", bbox_inches=\"tight\", dpi=300)\n",
    "\n",
    "# TOP\n",
    "plot_city_ranking(\n",
    "    city_metrics_df,\n",
    "    metric=\"mAP50-95\",\n",
    "    topk=10,\n",
    "    title=\"v7_full (obstáculo) — Top-10 ciudades por mAP50-95\",\n",
    "    out_base=EVAL_CITY_ROOT / \"top10_cities_map5095\"\n",
    ")\n",
    "\n",
    "# BOTTOM (orden inverso)\n",
    "plot_city_ranking(\n",
    "    city_metrics_df.sort_values(\"mAP50-95\", ascending=True),\n",
    "    metric=\"mAP50-95\",\n",
    "    topk=10,\n",
    "    title=\"v7_full (obstáculo) — Peor-10 ciudades por mAP50-95\",\n",
    "    out_base=EVAL_CITY_ROOT / \"bottom10_cities_map5095\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f0e12cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 660x420 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(6.6, 4.2))\n",
    "ax.scatter(city_metrics_df[\"n_obstaculos\"], city_metrics_df[\"mAP50-95\"], facecolors=\"white\", edgecolors=\"black\")\n",
    "ax.set_title(\"v7_full (obstáculo) — mAP50-95 vs nº instancias\", fontsize=14, fontfamily=\"serif\", pad=10)\n",
    "ax.set_xlabel(\"n_obstaculos (GT)\")\n",
    "ax.set_ylabel(\"mAP50-95\")\n",
    "\n",
    "ax.grid(True, linestyle=\":\", linewidth=0.9, alpha=0.35)\n",
    "for s in ax.spines.values():\n",
    "    s.set_visible(True)\n",
    "    s.set_linewidth(1.4)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c7762f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1150x460 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1150x460 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1150x460 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1150x460 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.transforms import ScaledTranslation\n",
    "\n",
    "def get_color_palette(n: int):\n",
    "    \"\"\"Paleta discreta profesional (tab10/tab20).\"\"\"\n",
    "    if n <= 10:\n",
    "        cmap = plt.get_cmap(\"tab10\")\n",
    "        return [cmap(i) for i in range(n)]\n",
    "    if n <= 20:\n",
    "        cmap = plt.get_cmap(\"tab20\")\n",
    "        return [cmap(i) for i in range(n)]\n",
    "    cmap = plt.get_cmap(\"hsv\", n)\n",
    "    return [cmap(i) for i in range(n)]\n",
    "\n",
    "def plot_city_ranking_safe(df, metric=\"recall\", topk=10, title=None, out_base=None, rotate=25):\n",
    "    d = df.sort_values(metric, ascending=False).head(topk).copy()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(11.5, 4.6), constrained_layout=False)\n",
    "    fig.subplots_adjust(top=0.84, bottom=0.28, left=0.08, right=0.98)\n",
    "\n",
    "    x = np.arange(len(d))\n",
    "    vals = d[metric].astype(float).values\n",
    "\n",
    "    colors = get_color_palette(len(d))\n",
    "\n",
    "    bars = ax.bar(\n",
    "        x, vals,\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=1.6,\n",
    "        color=colors,\n",
    "        alpha=0.85,\n",
    "        zorder=3\n",
    "    )\n",
    "\n",
    "    maxv = float(np.nanmax(vals)) if len(vals) else 0.0\n",
    "    top = maxv + max(0.12, 0.18 * maxv)\n",
    "    ax.set_ylim(0, min(1.2, top))\n",
    "\n",
    "    text_offset = ScaledTranslation(0, 10/72, fig.dpi_scale_trans)\n",
    "\n",
    "    for b, val in zip(bars, vals):\n",
    "        ax.text(\n",
    "            b.get_x() + b.get_width()/2,\n",
    "            val,\n",
    "            f\"{val:.2f}\",\n",
    "            transform=ax.transData + text_offset,\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=13,\n",
    "            zorder=5,\n",
    "            clip_on=False,\n",
    "            color=\"black\"\n",
    "        )\n",
    "\n",
    "    ax.set_title(\n",
    "        title or f\"v7_full (obstáculo) — Top-{topk} ciudades por {metric}\",\n",
    "        fontsize=30, fontfamily=\"serif\", pad=18\n",
    "    )\n",
    "\n",
    "    ax.set_ylabel(metric, fontsize=18)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(d[\"city\"].tolist(), rotation=rotate, ha=\"right\", fontsize=18)\n",
    "\n",
    "    ax.grid(True, axis=\"y\", linestyle=\":\", linewidth=0.9, alpha=0.30, zorder=0)\n",
    "\n",
    "    for s in ax.spines.values():\n",
    "        s.set_visible(True)\n",
    "        s.set_linewidth(2.0)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    if out_base:\n",
    "        out_base_color = str(out_base) + \"_color\"\n",
    "        fig.savefig(out_base_color + \".pdf\", bbox_inches=\"tight\", pad_inches=0.35, dpi=300)\n",
    "        fig.savefig(out_base_color + \".png\", bbox_inches=\"tight\", pad_inches=0.35, dpi=300)\n",
    "\n",
    "    plt.close(fig)\n",
    "\n",
    "plot_city_ranking_safe(city_metrics_df, metric=\"recall\", topk=10, out_base=EVAL_CITY_ROOT/\"top10_cities_recall\")\n",
    "plot_city_ranking_safe(city_metrics_df, metric=\"precision\", topk=10, out_base=EVAL_CITY_ROOT/\"top10_cities_precision\")\n",
    "plot_city_ranking_safe(city_metrics_df, metric=\"mAP50\", topk=10, out_base=EVAL_CITY_ROOT/\"top10_cities_map50\")\n",
    "plot_city_ranking_safe(city_metrics_df, metric=\"mAP50-95\", topk=10, out_base=EVAL_CITY_ROOT/\"top10_cities_map5095\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ee3196",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 820x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.transforms import ScaledTranslation\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8.2, 5.0), constrained_layout=False)\n",
    "fig.subplots_adjust(top=0.86, bottom=0.16, left=0.12, right=0.98)\n",
    "\n",
    "x = city_metrics_df[\"recall\"].astype(float).values\n",
    "y = city_metrics_df[\"precision\"].astype(float).values\n",
    "cities = city_metrics_df[\"city\"].astype(str).values\n",
    "\n",
    "ax.scatter(\n",
    "    x, y,\n",
    "    s=85,\n",
    "    facecolors=\"white\",\n",
    "    edgecolors=\"black\",\n",
    "    linewidths=1.8,\n",
    "    zorder=3\n",
    ")\n",
    "\n",
    "xmin, xmax = np.nanmin(x), np.nanmax(x)\n",
    "ymin, ymax = np.nanmin(y), np.nanmax(y)\n",
    "xpad = max(0.02, 0.10 * (xmax - xmin))\n",
    "ypad = max(0.02, 0.12 * (ymax - ymin))\n",
    "ax.set_xlim(max(0.0, xmin - xpad), min(1.0, xmax + xpad))\n",
    "ax.set_ylim(max(0.0, ymin - ypad), min(1.0, ymax + ypad))\n",
    "\n",
    "text_offset = ScaledTranslation(6/72, 3/72, fig.dpi_scale_trans)\n",
    "for xi, yi, city in zip(x, y, cities):\n",
    "    ax.text(\n",
    "        xi, yi, city,\n",
    "        transform=ax.transData + text_offset,\n",
    "        fontsize=13,\n",
    "        fontfamily=\"serif\",\n",
    "        ha=\"left\",\n",
    "        va=\"center\",\n",
    "        clip_on=False,\n",
    "        zorder=5\n",
    "    )\n",
    "\n",
    "ax.set_title(\"v7_full (obstáculo) — Precision vs Recall por ciudad\",\n",
    "             fontsize=28, fontfamily=\"serif\", pad=14)\n",
    "ax.set_xlabel(\"recall\", fontsize=20)\n",
    "ax.set_ylabel(\"precision\", fontsize=20)\n",
    "\n",
    "ax.grid(True, linestyle=\":\", linewidth=0.9, alpha=0.35, zorder=0)\n",
    "\n",
    "for s in ax.spines.values():\n",
    "    s.set_visible(True)\n",
    "    s.set_linewidth(2.0)\n",
    "\n",
    "ax.tick_params(axis=\"both\", labelsize=16)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Guardado SIN espacios raros\n",
    "fig.savefig(EVAL_CITY_ROOT / \"scatter_precision_vs_recall_cities_pretty.pdf\",\n",
    "            bbox_inches=\"tight\", pad_inches=0.15, dpi=300)\n",
    "fig.savefig(EVAL_CITY_ROOT / \"scatter_precision_vs_recall_cities_pretty.png\",\n",
    "            bbox_inches=\"tight\", pad_inches=0.15, dpi=300)\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc7b4b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      " - augmented_outputs\\gsv-chicago-86-Obstacle_GEOM_da_geom_only.png\n",
      " - augmented_outputs\\gsv-chicago-86-Obstacle_COLOR_da_color_only.png\n",
      " - augmented_outputs\\gsv-chicago-86-Obstacle_COMBINED_da_baseline_soft_hsv.png\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "IMG_DIR  = r\"C:\\Users\\joano\\Desktop\\trabajo_final_master\\data\\images\\annotated_images\"\n",
    "IMAGE_NAME = \"gsv-chicago-86-Obstacle.png\"\n",
    "\n",
    "OUT_DIR = \"augmented_outputs\"\n",
    "Path(OUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "AUGS = {\n",
    "    \"da_geom_only\": {\n",
    "        \"hsv_h\": 0.0, \"hsv_s\": 0.0, \"hsv_v\": 0.0,\n",
    "        \"degrees\": 2, \"translate\": 0.08, \"scale\": 0.5, \"perspective\": 0.0005,\n",
    "        \"fliplr\": 0.5, \"flipud\": 0.0,\n",
    "    },\n",
    "    \"da_color_only\": {\n",
    "        \"hsv_h\": 0.015, \"hsv_s\": 0.6, \"hsv_v\": 0.35,\n",
    "        \"degrees\": 0.5, \"translate\": 0.02, \"scale\": 0.2, \"perspective\": 0.0,\n",
    "        \"fliplr\": 0.5, \"flipud\": 0.0,\n",
    "    },\n",
    "    \"da_baseline_soft_hsv\": {\n",
    "        \"hsv_h\": 0.01, \"hsv_s\": 0.35, \"hsv_v\": 0.20,\n",
    "        \"degrees\": 2, \"translate\": 0.08, \"scale\": 0.5, \"perspective\": 0.0005,\n",
    "        \"fliplr\": 0.5, \"flipud\": 0.0,\n",
    "    },\n",
    "}\n",
    "\n",
    "def find_image_path(img_dir: str, image_name: str) -> Path:\n",
    "    p = Path(img_dir) / image_name\n",
    "    if p.exists():\n",
    "        return p\n",
    "    matches = list(Path(img_dir).rglob(image_name))\n",
    "    if matches:\n",
    "        return matches[0]\n",
    "    raise FileNotFoundError(f\"Image '{image_name}' not found in '{img_dir}' (or its subfolders).\")\n",
    "\n",
    "def _perspective_coeffs(dst_pts, src_pts):\n",
    "    A, B = [], []\n",
    "    for (x, y), (u, v) in zip(dst_pts, src_pts):\n",
    "        A.append([x, y, 1, 0, 0, 0, -u*x, -u*y])\n",
    "        A.append([0, 0, 0, x, y, 1, -v*x, -v*y])\n",
    "        B.append(u)\n",
    "        B.append(v)\n",
    "    A = np.array(A, dtype=np.float64)\n",
    "    B = np.array(B, dtype=np.float64)\n",
    "    coeffs = np.linalg.lstsq(A, B, rcond=None)[0]\n",
    "    return coeffs.tolist()\n",
    "\n",
    "def apply_hsv_jitter(img: Image.Image, hsv_h: float, hsv_s: float, hsv_v: float) -> Image.Image:\n",
    "    if hsv_h == 0 and hsv_s == 0 and hsv_v == 0:\n",
    "        return img\n",
    "\n",
    "    hsv = img.convert(\"HSV\")\n",
    "    h, s, v = hsv.split()\n",
    "\n",
    "    h_np = np.array(h, dtype=np.int16)\n",
    "    s_np = np.array(s, dtype=np.float32)\n",
    "    v_np = np.array(v, dtype=np.float32)\n",
    "\n",
    "    dh = int(round(random.uniform(-hsv_h, hsv_h) * 255))\n",
    "    h_np = (h_np + dh) % 256\n",
    "    h_np = h_np.astype(np.uint8)\n",
    "\n",
    "    sat_gain = random.uniform(1 - hsv_s, 1 + hsv_s) if hsv_s > 0 else 1.0\n",
    "    val_gain = random.uniform(1 - hsv_v, 1 + hsv_v) if hsv_v > 0 else 1.0\n",
    "\n",
    "    s_np = np.clip(s_np * sat_gain, 0, 255).astype(np.uint8)\n",
    "    v_np = np.clip(v_np * val_gain, 0, 255).astype(np.uint8)\n",
    "\n",
    "    out = Image.merge(\"HSV\", (Image.fromarray(h_np),\n",
    "                              Image.fromarray(s_np),\n",
    "                              Image.fromarray(v_np))).convert(\"RGB\")\n",
    "    return out\n",
    "\n",
    "def apply_geometric(img: Image.Image, degrees: float, translate: float, scale: float,\n",
    "                    perspective: float, fliplr: float, flipud: float,\n",
    "                    fill=(114,114,114)) -> Image.Image:\n",
    "    w, h = img.size\n",
    "\n",
    "    if fliplr > 0 and random.random() < fliplr:\n",
    "        img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    if flipud > 0 and random.random() < flipud:\n",
    "        img = img.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "\n",
    "    angle = random.uniform(-degrees, degrees) if degrees else 0.0\n",
    "    sc = 1.0 + random.uniform(-scale, scale) if scale else 1.0\n",
    "    dx = random.uniform(-translate, translate) * w if translate else 0.0\n",
    "    dy = random.uniform(-translate, translate) * h if translate else 0.0\n",
    "\n",
    "    cx, cy = w / 2.0, h / 2.0\n",
    "    rad = np.deg2rad(angle)\n",
    "    cos_a, sin_a = np.cos(rad), np.sin(rad)\n",
    "\n",
    "    C1 = np.array([[1, 0, -cx],\n",
    "                   [0, 1, -cy],\n",
    "                   [0, 0, 1]], dtype=np.float64)\n",
    "\n",
    "    RS = np.array([[sc*cos_a, -sc*sin_a, 0],\n",
    "                   [sc*sin_a,  sc*cos_a, 0],\n",
    "                   [0, 0, 1]], dtype=np.float64)\n",
    "\n",
    "    C2 = np.array([[1, 0, cx + dx],\n",
    "                   [0, 1, cy + dy],\n",
    "                   [0, 0, 1]], dtype=np.float64)\n",
    "\n",
    "    forward = C2 @ RS @ C1\n",
    "    inv = np.linalg.inv(forward)\n",
    "    a, b, c = inv[0, 0], inv[0, 1], inv[0, 2]\n",
    "    d, e, f = inv[1, 0], inv[1, 1], inv[1, 2]\n",
    "\n",
    "    img = img.transform((w, h), Image.AFFINE, (a, b, c, d, e, f),\n",
    "                        resample=Image.BICUBIC, fillcolor=fill)\n",
    "\n",
    "    if perspective and perspective > 0:\n",
    "        jitter = perspective * max(w, h)\n",
    "        src = [(0,0), (w,0), (w,h), (0,h)]\n",
    "        dst = [(0 + random.uniform(-jitter, jitter), 0 + random.uniform(-jitter, jitter)),\n",
    "               (w + random.uniform(-jitter, jitter), 0 + random.uniform(-jitter, jitter)),\n",
    "               (w + random.uniform(-jitter, jitter), h + random.uniform(-jitter, jitter)),\n",
    "               (0 + random.uniform(-jitter, jitter), h + random.uniform(-jitter, jitter))]\n",
    "        coeffs = _perspective_coeffs(dst, src)\n",
    "        img = img.transform((w, h), Image.PERSPECTIVE, coeffs,\n",
    "                            resample=Image.BICUBIC, fillcolor=fill)\n",
    "\n",
    "    return img\n",
    "\n",
    "def apply_aug_variant(img: Image.Image, cfg: dict, seed: int) -> Image.Image:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    out = img.copy()\n",
    "    out = apply_geometric(\n",
    "        out,\n",
    "        degrees=cfg[\"degrees\"],\n",
    "        translate=cfg[\"translate\"],\n",
    "        scale=cfg[\"scale\"],\n",
    "        perspective=cfg[\"perspective\"],\n",
    "        fliplr=cfg[\"fliplr\"],\n",
    "        flipud=cfg[\"flipud\"],\n",
    "    )\n",
    "    out = apply_hsv_jitter(out, cfg[\"hsv_h\"], cfg[\"hsv_s\"], cfg[\"hsv_v\"])\n",
    "    return out\n",
    "\n",
    "def show_single(title: str, im: Image.Image):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(im)\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "img_path = find_image_path(IMG_DIR, IMAGE_NAME)\n",
    "img0 = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "variants = [\n",
    "    (\"GEOM\", \"da_geom_only\", 13),\n",
    "    (\"COLOR\", \"da_color_only\", 21),\n",
    "    (\"COMBINED\", \"da_baseline_soft_hsv\", 37),\n",
    "]\n",
    "\n",
    "show_single(\"ORIGINAL\", img0)\n",
    "\n",
    "saved_paths = []\n",
    "\n",
    "for tag, key, seed in variants:\n",
    "    img_aug = apply_aug_variant(img0, AUGS[key], seed=seed)\n",
    "\n",
    "    fname = f\"{Path(IMAGE_NAME).stem}_{tag}_{key}.png\"\n",
    "    out_path = Path(OUT_DIR) / fname\n",
    "    img_aug.save(out_path)\n",
    "    saved_paths.append(out_path)\n",
    "\n",
    "    show_single(f\"{tag} ({key})\", img_aug)\n",
    "\n",
    "print(\"Saved:\")\n",
    "for p in saved_paths:\n",
    "    print(\" -\", p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "va-sidewalks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
